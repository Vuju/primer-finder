{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-11T13:47:05.641435Z",
     "start_time": "2025-05-11T13:47:05.621497Z"
    }
   },
   "source": [
    "\n",
    "import sqlite3\n",
    "import multiprocessing as mp\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "import logging\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class DatabaseConnector(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for database connections.\n",
    "    Allows for different database implementations.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def connect(self):\n",
    "        \"\"\"Establish a connection to the database\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def close(self):\n",
    "        \"\"\"Close the database connection\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_total_specimens(self) -> int:\n",
    "        \"\"\"Return total number of specimens in the database\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_specimens_batch(self, batch_size: int, offset: int) -> List[Tuple[int, str]]:\n",
    "        \"\"\"Get a batch of specimens (id, sequence)\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_specimens_with_primer_match(self, primer: str, batch_size: int, offset: int) -> List[Tuple[int, str, Optional[int]]]:\n",
    "        \"\"\"Get specimens with their existing primer matches\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def insert_primer_matches(self, matches: List[Tuple[int, str, int]]):\n",
    "        \"\"\"Bulk insert new primer matches\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_primer_matches_table(self):\n",
    "        \"\"\"Create the primer_matches table if it doesn't exist\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class SQLiteConnector(DatabaseConnector):\n",
    "    \"\"\"\n",
    "    SQLite implementation of the DatabaseConnector\n",
    "    \"\"\"\n",
    "    def __init__(self, db_path: str, **kwargs):\n",
    "        self.db_path = db_path\n",
    "        self.conn = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Called when entering a 'with' block\"\"\"\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Called when exiting a 'with' block\"\"\"\n",
    "        if hasattr(self, 'connection') and self.connection:\n",
    "            self.conn.close()\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Establish a connection to the SQLite database\"\"\"\n",
    "\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        return self\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the SQLite connection\"\"\"\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "            self.conn = None\n",
    "            self.cursor = None\n",
    "\n",
    "    def get_total_specimens(self) -> int:\n",
    "        \"\"\"Return total number of specimens in the database\"\"\"\n",
    "        self.cursor.execute(\"SELECT COUNT(*) FROM specimen\")\n",
    "        return self.cursor.fetchone()[0]\n",
    "\n",
    "    def get_specimens_batch(self, batch_size: int, offset: int) -> List[Tuple[int, str]]:\n",
    "        \"\"\"Get a batch of specimens (id, sequence)\"\"\"\n",
    "        self.cursor.execute(\"\"\"\n",
    "            SELECT specimenid, sequence\n",
    "            FROM specimen\n",
    "            ORDER BY specimenid\n",
    "            LIMIT ? OFFSET ?\n",
    "        \"\"\", (batch_size, offset))\n",
    "        return self.cursor.fetchall()\n",
    "\n",
    "    def get_specimens_with_primer_match(self, primer: str, batch_size: int, offset: int) -> List[Tuple[int, str, Optional[int]]]:\n",
    "        \"\"\"Get specimens with their existing primer matches\"\"\"\n",
    "        self.cursor.execute(\"\"\"\n",
    "            SELECT s.specimenid, s.nuc_san, pm.primer_start_index\n",
    "            FROM specimen s\n",
    "            LEFT JOIN primer_matches pm ON s.specimenid = pm.specimenid AND pm.primer_sequence = ?\n",
    "            ORDER BY s.specimenid\n",
    "            LIMIT ? OFFSET ?\n",
    "        \"\"\", (primer, batch_size, offset))\n",
    "        return self.cursor.fetchall()\n",
    "\n",
    "    def insert_primer_matches(self, matches: List[Tuple[int, str, int]]):\n",
    "        \"\"\"Bulk insert new primer matches\"\"\"\n",
    "        if matches:\n",
    "            self.cursor.executemany(\"\"\"\n",
    "                INSERT INTO primer_matches (specimenid, primer_sequence, primer_start_index)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\", matches)\n",
    "            self.conn.commit()\n",
    "\n",
    "    def create_primer_matches_table(self):\n",
    "        \"\"\"Create the primer_matches table if it doesn't exist\"\"\"\n",
    "        self.cursor.execute(\"\"\"\n",
    "        DROP TABLE primer_matches\n",
    "        \"\"\")\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS primer_matches (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            specimenid INTEGER NOT NULL,\n",
    "            primer_sequence TEXT NOT NULL,\n",
    "            primer_start_index INTEGER NOT NULL,\n",
    "            FOREIGN KEY (specimenid) REFERENCES specimen(specimenid),\n",
    "            UNIQUE (specimenid, primer_sequence)\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "        self.cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_primer_matches ON primer_matches (specimenid, primer_sequence)\")\n",
    "        self.conn.commit()\n",
    "\n",
    "\n",
    "def find_primer_match(sequence: str, primer: str) -> int:\n",
    "    \"\"\"\n",
    "    Find the position of primer in sequence.\n",
    "    Returns position (0-based) or -1 if not found.\n",
    "\n",
    "    This could be enhanced with more sophisticated matching algorithms\n",
    "    like Smith-Waterman or PCR-specific algorithms.\n",
    "    \"\"\"\n",
    "    return sequence.find(primer)\n",
    "\n",
    "\n",
    "def process_batch(args: Tuple) -> List[Tuple[int, str, int]]:\n",
    "    \"\"\"\n",
    "    Process a batch of specimens for a specific primer.\n",
    "    This function runs in a separate process.\n",
    "\n",
    "    Args:\n",
    "        args: Tuple containing (db_path, primer, batch_data)\n",
    "\n",
    "    Returns:\n",
    "        List of tuples (specimenid, primer_sequence, match_position)\n",
    "    \"\"\"\n",
    "    db_path, primer, batch_data = args\n",
    "\n",
    "    results = []\n",
    "    for specimenid, sequence, match_position in batch_data:\n",
    "        if match_position is None:  # No match exists yet\n",
    "            new_match_position = find_primer_match(sequence, primer)\n",
    "            results.append((specimenid, primer, new_match_position))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "class PrimerMatchProcessor:\n",
    "    \"\"\"\n",
    "    Main class for processing primer matches using multiprocessing\n",
    "    \"\"\"\n",
    "    def __init__(self, db_connector: DatabaseConnector, primers: List[str], batch_size: int = 1000,\n",
    "                 max_workers: int = None):\n",
    "        \"\"\"\n",
    "        Initialize the processor\n",
    "\n",
    "        Args:\n",
    "            db_connector: Database connector instance\n",
    "            primers: List of primer sequences to search for\n",
    "            batch_size: Size of batches to process\n",
    "            max_workers: Maximum number of worker processes (defaults to CPU count)\n",
    "        \"\"\"\n",
    "        self.db_connector = db_connector\n",
    "        self.primers = primers\n",
    "        self.batch_size = batch_size\n",
    "        self.max_workers = max_workers or mp.cpu_count()\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Process all specimens for all primers\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"Starting primer match processing with {self.max_workers} workers\")\n",
    "\n",
    "        # Ensure the table exists\n",
    "        with self.db_connector.connect() as db:\n",
    "            db.create_primer_matches_table()\n",
    "            total_specimens = db.get_total_specimens()\n",
    "\n",
    "        logger.info(f\"Processing {total_specimens} specimens for {len(self.primers)} primers\")\n",
    "\n",
    "        # Process each primer\n",
    "        for primer in self.primers:\n",
    "            self._process_primer(primer, total_specimens)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Completed processing in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    def _process_primer(self, primer: str, total_specimens: int):\n",
    "        \"\"\"\n",
    "        Process all specimens for a single primer\n",
    "\n",
    "        Args:\n",
    "            primer: Primer sequence to search for\n",
    "            total_specimens: Total number of specimens\n",
    "        \"\"\"\n",
    "        logger.info(f\"Processing primer: {primer}\")\n",
    "        db = self.db_connector.connect()\n",
    "        try:\n",
    "            total_specimens = db.get_total_specimens()\n",
    "\n",
    "            for offset in range(0, total_specimens, self.batch_size):\n",
    "                batch_start_time = time.time()\n",
    "\n",
    "                # Get specimens with their existing matches for this primer\n",
    "                with self.db_connector.connect() as db:\n",
    "                    batch_data = db.get_specimens_with_primer_match(primer, self.batch_size, offset)\n",
    "\n",
    "                # Split the batch into chunks for parallel processing\n",
    "                chunk_size = len(batch_data) // self.max_workers\n",
    "                if chunk_size == 0:\n",
    "                    chunk_size = len(batch_data)\n",
    "\n",
    "                chunks = [batch_data[i:i + chunk_size] for i in range(0, len(batch_data), chunk_size)]\n",
    "\n",
    "                # Process chunks in parallel\n",
    "                with ProcessPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "                    db_path = self.db_connector.db_path if hasattr(self.db_connector, 'db_path') else None\n",
    "                    results = list(executor.map(process_batch, [(db_path, primer, chunk) for chunk in chunks]))\n",
    "\n",
    "                # Flatten results\n",
    "                all_matches = [match for sublist in results for match in sublist]\n",
    "\n",
    "                # Insert results\n",
    "                if all_matches:\n",
    "                    with self.db_connector.connect() as db:\n",
    "                        db.insert_primer_matches(all_matches)\n",
    "\n",
    "                batch_time = time.time() - batch_start_time\n",
    "                progress = min(offset + self.batch_size, total_specimens)\n",
    "\n",
    "                logger.info(f\"Processed {progress}/{total_specimens} specimens for primer {primer} \" +\n",
    "                          f\"({len(all_matches)} new matches, {batch_time:.2f}s)\")\n",
    "        finally:\n",
    "            if hasattr(db, 'close'):\n",
    "                db.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    db_path = \"/mnt/z/Uni/Master Thesis/eyeBOLD/eyeBOLD_mini.db\"\n",
    "    primers = [\"ATTACCGCGGCTGCTGG\", \"CCTACGGGAGGCAGCAG\"]  # Example 16S rRNA primers\n",
    "    batch_size = 5000\n",
    "    max_workers = min(mp.cpu_count(), 8)  # Limit to 8 processes max\n",
    "\n",
    "    # Initialize the database connector\n",
    "    db_connector = SQLiteConnector(db_path)\n",
    "\n",
    "    # Create and run the processor\n",
    "    processor = PrimerMatchProcessor(\n",
    "        db_connector=db_connector,\n",
    "        primers=primers,\n",
    "        batch_size=batch_size,\n",
    "        max_workers=max_workers\n",
    "    )\n",
    "\n",
    "    processor.process()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T13:47:09.380591Z",
     "start_time": "2025-05-11T13:47:05.655802Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "9187e774d96408a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 15:47:05,666 - __main__ - INFO - Starting primer match processing with 4 workers\n",
      "2025-05-11 15:47:05,721 - __main__ - INFO - Processing 7000 specimens for 2 primers\n",
      "2025-05-11 15:47:05,722 - __main__ - INFO - Processing primer: ATTACCGCGGCTGCTGG\n",
      "2025-05-11 15:47:06,552 - __main__ - INFO - Processed 5000/7000 specimens for primer ATTACCGCGGCTGCTGG (5000 new matches, 0.82s)\n",
      "2025-05-11 15:47:07,430 - __main__ - INFO - Processed 7000/7000 specimens for primer ATTACCGCGGCTGCTGG (2000 new matches, 0.88s)\n",
      "2025-05-11 15:47:07,432 - __main__ - INFO - Processing primer: CCTACGGGAGGCAGCAG\n",
      "2025-05-11 15:47:08,233 - __main__ - INFO - Processed 5000/7000 specimens for primer CCTACGGGAGGCAGCAG (5000 new matches, 0.79s)\n",
      "2025-05-11 15:47:09,375 - __main__ - INFO - Processed 7000/7000 specimens for primer CCTACGGGAGGCAGCAG (2000 new matches, 1.14s)\n",
      "2025-05-11 15:47:09,377 - __main__ - INFO - Completed processing in 3.71 seconds\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
